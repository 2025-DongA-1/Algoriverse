import sys
import os
from dotenv import load_dotenv

# 1. í˜„ì¬ íŒŒì¼ì˜ ìœ„ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ 'bias_model' í´ë”(ë£¨íŠ¸) ì°¾ê¸°
# (scripts í´ë” -> í•œ ì¹¸ ìœ„ bias_model í´ë”)
current_dir = os.path.dirname(os.path.abspath(__file__))
BASE_DIR = os.path.dirname(current_dir)

# 2. ì‹œìŠ¤í…œ ê²½ë¡œ ì¶”ê°€ (analysis_service importìš©)
sys.path.append(BASE_DIR)

# 3. â˜… í•µì‹¬: .env íŒŒì¼ ê²½ë¡œë¥¼ ì§ì ‘ ë§Œë“¤ì–´ì„œ ë¡œë”©í•˜ê¸°
env_path = os.path.join(BASE_DIR, '.env')

# .env íŒŒì¼ ë¡œë”© ì‹œë„
if os.path.exists(env_path):
    load_dotenv(env_path)
    print(f"âœ… .env íŒŒì¼ ë°œê²¬ ë° ë¡œë“œ: {env_path}")
else:
    print(f"âŒ .env íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤! ê²½ë¡œ: {env_path}")

# ========================================================
# 4. ëª¨ë“ˆ Import & ì„¤ì •
# ========================================================
from analysis_service import BiasAnalyzer
import pandas as pd
import requests
import re
import pymysql
import time
from tqdm import tqdm

# 5. API í‚¤ í™•ì¸ (ë””ë²„ê¹…ìš© - ì‹¤í–‰ ì‹œ IDê°€ ë³´ì—¬ì•¼ ì„±ê³µ!)
NAVER_CLIENT_ID = os.getenv("NAVER_CLIENT_ID")
NAVER_CLIENT_SECRET = os.getenv("NAVER_CLIENT_SECRET")

print(f"ğŸ” [ë””ë²„ê·¸] ë¡œë“œëœ Client ID: {NAVER_CLIENT_ID}") 

if not NAVER_CLIENT_ID:
    print("ğŸš¨ [ë¹„ìƒ] í‚¤ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env ìœ„ì¹˜ë¥¼ í™•ì¸í•˜ê±°ë‚˜ í‚¤ë¥¼ ì§ì ‘ ì…ë ¥í•˜ì„¸ìš”.")
    # (ê¸‰í•˜ë©´ ì—¬ê¸°ì— ì§ì ‘ í‚¤ë¥¼ ì ìœ¼ì„¸ìš”)
    # NAVER_CLIENT_ID = "ë„¤ì´ë²„_ì•„ì´ë””_ì§ì ‘ì…ë ¥"
    # NAVER_CLIENT_SECRET = "ë„¤ì´ë²„_ë¹„ë²ˆ_ì§ì ‘ì…ë ¥"

DB_HOST = os.getenv("DB_HOST")
DB_USER = os.getenv("DB_USER")
DB_PASS = os.getenv("DB_PASS")
DB_NAME = os.getenv("DB_NAME")
# í¬íŠ¸ëŠ” int ë³€í™˜ ì‹œ ì—ëŸ¬ ë‚  ìˆ˜ ìˆìœ¼ë‹ˆ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
try:
    DB_PORT = int(os.getenv("DB_PORT"))
except:
    DB_PORT = 3306 # ê¸°ë³¸ê°’

# ========================================================
# 5. í‚¤ì›Œë“œ íŒŒì¼(CSV) ê²½ë¡œ ì„¤ì •
# ========================================================
# bias_model/data/bias_data_final.csv
KEYWORDS_FILE = os.path.join(BASE_DIR, 'data', 'bias_data_final.csv')

# íŒŒì¼ ì§„ì§œ ìˆë‚˜ í™•ì¸ (ë””ë²„ê¹…ìš©)
if not os.path.exists(KEYWORDS_FILE):
    print(f"âŒ ì˜¤ë¥˜: ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
    print(f"ğŸ‘‰ ê²½ë¡œ í™•ì¸: {KEYWORDS_FILE}")
    
    
# â˜… í•œ í‚¤ì›Œë“œë‹¹ ê°€ì ¸ì˜¬ ê¸°ì‚¬ ìˆ˜ (ìµœëŒ€ 1000)
# 100ìœ¼ë¡œ ì„¤ì •í•˜ë©´ -> 115ê°œ í‚¤ì›Œë“œ * 100 = 11,500ê°œ (ì•½ 20ë¶„ ì†Œìš”)
# 500ìœ¼ë¡œ ì„¤ì •í•˜ë©´ -> 115ê°œ í‚¤ì›Œë“œ * 500 = 57,500ê°œ (ì•½ 1ì‹œê°„+ ì†Œìš”, 6ê°œì›”ì¹˜ ì¶©ë¶„)
MAX_NEWS_PER_KEYWORD = 500 

def get_naver_news_past(keyword, total_count):
    news_list = []
    # 100ê°œì”© ëŠì–´ì„œ ê³¼ê±° í˜ì´ì§€ë¡œ ë„˜ì–´ê° (Pagination)
    for start_index in range(1, total_count, 100):
        if start_index > 1000: break # ë„¤ì´ë²„ API ìµœëŒ€ í•œê³„

        url = "https://openapi.naver.com/v1/search/news.json"
        headers = {"X-Naver-Client-Id": NAVER_CLIENT_ID, "X-Naver-Client-Secret": NAVER_CLIENT_SECRET}
        params = {
            "query": keyword,
            "display": 100,
            "start": start_index, 
            "sort": "sim"  # 'sim'(ì •í™•ë„ìˆœ)ì„ ì“°ë©´ ê³¼ê±°ì˜ ì¤‘ìš”í•œ ê¸°ì‚¬ë„ ì˜ ë‚˜ì˜µë‹ˆë‹¤.
                           # 'date'(ë‚ ì§œìˆœ)ì„ ì“°ë©´ ë¬´ì¡°ê±´ ìµœì‹ ë¶€í„° ê°€ì ¸ì˜µë‹ˆë‹¤.
        }
        try:
            resp = requests.get(url, headers=headers, params=params)
            if resp.status_code == 200:
                items = resp.json().get('items', [])
                if not items: break
                news_list.extend(items)
            else:
                print(f"API Error: {resp.status_code}")
                break
        except Exception as e:
            print(f"Request Error: {e}")
            break
        
        time.sleep(0.3) # API ë³´í˜¸ìš© ë”œë ˆì´
        
    return news_list[:total_count]

def save_bulk_to_db(data_list):
    if not data_list: return
    conn = None
    try:
        conn = pymysql.connect(host=DB_HOST, user=DB_USER, password=DB_PASS, db=DB_NAME, port=DB_PORT, charset='utf8')
        cur = conn.cursor()
        
        # main.py ê¸°ì¤€ í…Œì´ë¸” ì»¬ëŸ¼ì— ë§ì¶¤
        sql = "INSERT INTO news (category, title, link, description) VALUES (%s, %s, %s, %s)"
        
        success = 0
        # executemanyë¥¼ ì“°ë©´ ë” ë¹ ë¥´ì§€ë§Œ, ì˜¤ë¥˜ í™•ì¸ì„ ìœ„í•´ ë°˜ë³µë¬¸ ì‚¬ìš©
        for item in data_list:
            try:
                cur.execute(sql, (item['category'], item['title'], item['link'], item['description']))
                success += 1
            except:
                pass # ì¤‘ë³µ ê¸°ì‚¬ ë“±ì€ ë¬´ì‹œ
        
        conn.commit()
        # ì¤‘ê°„ ì ê²€ ì¶œë ¥
        if success > 0:
            print(f"   â””â”€ {success}ê±´ ì €ì¥ ì™„ë£Œ")
        
    except Exception as e:
        print(f"DB Error: {e}")
    finally:
        if conn: conn.close()

def main():
    # 1. í‚¤ì›Œë“œ íŒŒì¼ ë¡œë“œ
    try:
        df = pd.read_csv(KEYWORDS_FILE)
    except:
        df = pd.read_csv(KEYWORDS_FILE, encoding='cp949')

    print(f"ğŸš€ ì´ {len(df)}ê°œì˜ í‚¤ì›Œë“œë¡œ ëŒ€ëŸ‰ ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤. (ëª©í‘œ: í‚¤ì›Œë“œë‹¹ {MAX_NEWS_PER_KEYWORD}ê°œ)")
    
    # 2. í‚¤ì›Œë“œë³„ ìˆ˜ì§‘ ë°˜ë³µ
    for i, row in tqdm(df.iterrows(), total=len(df), desc="ì „ì²´ ì§„í–‰ë¥ "):
        keyword = row['keyword']
        category = row['category']
        
        # ê¸°ì‚¬ ìˆ˜ì§‘
        items = get_naver_news_past(keyword, MAX_NEWS_PER_KEYWORD)
        
        # DB ì €ì¥ìš© ë°ì´í„° ê°€ê³µ
        db_data = []
        for item in items:
            title = re.sub(r'<.*?>|&quot;|&gt;|&lt;', '', item['title'])
            desc = re.sub(r'<.*?>|&quot;|&gt;|&lt;', '', item['description'])
            
            db_data.append({
                'category': category,
                'title': title,
                'link': item['originallink'] or item['link'],
                'description': desc
            })
        
        # ë°”ë¡œë°”ë¡œ ì €ì¥ (ë©”ëª¨ë¦¬ ì ˆì•½)
        save_bulk_to_db(db_data)
        time.sleep(0.5)

    print("\nğŸ‰ 6ê°œì›”ì¹˜(ì¶”ì •) ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ! export_csv.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")

if __name__ == "__main__":
    main()