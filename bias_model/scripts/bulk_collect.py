import sys
import os

# í˜„ì¬ íŒŒì¼ì˜ ìœ„ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ, í•œ ë‹¨ê³„ ìœ„(ë¶€ëª¨ í´ë”)ë¥¼ ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname(__file__))))

# (ì´ ì•„ë˜ì— ì›ë˜ ìˆë˜ import ì½”ë“œë“¤ì´ ì˜¤ë©´ ë©ë‹ˆë‹¤)
from analysis_service import BiasAnalyzer
import pandas as pd
import requests
import re
import pymysql
import time
from tqdm import tqdm
from dotenv import load_dotenv

# .env íŒŒì¼ì— ìˆëŠ” ë‚´ìš©ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤
load_dotenv()


# ==========================================
# [ì„¤ì •] ë³¸ì¸ì˜ DB ì •ë³´ ë° API í‚¤
# ==========================================
NAVER_CLIENT_ID = os.getenv("NAVER_CLIENT_ID")     
NAVER_CLIENT_SECRET = os.getenv("NAVER_CLIENT_SECRET") 

DB_HOST = os.getenv("DB_HOST")
DB_USER = os.getenv("DB_USER")
DB_PASS = os.getenv("DB_PASS")
DB_NAME = os.getenv("DB_NAME")
DB_PORT = int(os.getenv("DB_PORT"))

# â˜… ëª©í‘œ: ì¹´í…Œê³ ë¦¬ë³„ë¡œ 1000ê°œì”© -> ì´ 5000ê°œ ìˆ˜ì§‘ ë„ì „!
TARGET_CATEGORIES = ['ì •ì¹˜ ì™¸êµ', 'ì •ì¹˜ ì•ˆë³´', 'ì •ì¹˜ ì‚¬ë²•', 'ì •ì¹˜ ë…¸ë™', 'ì •ì¹˜ í™˜ê²½']
MAX_NEWS_PER_CATEGORY = 1000 

def get_naver_news_bulk(keyword, total_count):
    news_list = []
    # ë„¤ì´ë²„ APIëŠ” í•œ ë²ˆì— 100ê°œê¹Œì§€ë§Œ ì¤Œ -> ë°˜ë³µ í˜¸ì¶œ í•„ìš”
    for start_index in range(1, total_count, 100):
        url = "https://openapi.naver.com/v1/search/news.json"
        headers = {"X-Naver-Client-Id": NAVER_CLIENT_ID, "X-Naver-Client-Secret": NAVER_CLIENT_SECRET}
        params = {
            "query": keyword,
            "display": 100, # ìµœëŒ€ 100
            "start": start_index, 
            "sort": "sim" # ì •í™•ë„ìˆœ (ë˜ëŠ” 'date' ìµœì‹ ìˆœ)
        }
        try:
            resp = requests.get(url, headers=headers, params=params)
            if resp.status_code == 200:
                items = resp.json().get('items', [])
                if not items: break # ë” ì´ìƒ ê¸°ì‚¬ê°€ ì—†ìœ¼ë©´ ì¤‘ë‹¨
                news_list.extend(items)
            else:
                print(f"API Error: {resp.status_code}")
                break
        except Exception as e:
            print(f"Request Error: {e}")
            break
        
        time.sleep(0.5) # API ë§¤ë„ˆ
        
    return news_list[:total_count] # ì •í™•íˆ ëª©í‘œ ê°œìˆ˜ë§Œí¼ ìë¥´ê¸°

def save_bulk_to_db(data_list):
    if not data_list: return
    conn = None
    try:
        conn = pymysql.connect(host=DB_HOST, user=DB_USER, password=DB_PASS, db=DB_NAME, port=DB_PORT, charset='utf8')
        cur = conn.cursor()
        
        sql = "INSERT INTO news (category, title, link, description) VALUES (%s, %s, %s, %s)"
        
        success = 0
        for item in tqdm(data_list, desc="DB ì €ì¥ ì¤‘"):
            try:
                cur.execute(sql, (item['category'], item['title'], item['link'], item['description']))
                success += 1
            except:
                pass # ì¤‘ë³µ í‚¤ ì—ëŸ¬ ë“±ì€ ë¬´ì‹œ
        
        conn.commit()
        print(f"âœ… ì´ {success}ê±´ ì‹ ê·œ ì €ì¥ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"DB Error: {e}")
    finally:
        if conn: conn.close()

def main():
    print("ğŸš€ ê³¼ê±° ê¸°ì‚¬ ëŒ€ëŸ‰ ìˆ˜ì§‘ ì‹œì‘...")
    all_data = []
    
    for category in TARGET_CATEGORIES:
        print(f"\n[{category}] ë¶„ì•¼ ìˆ˜ì§‘ ì¤‘...")
        items = get_naver_news_bulk(category, MAX_NEWS_PER_CATEGORY)
        
        for item in items:
            title = re.sub(r'<.*?>|&quot;|&gt;|&lt;', '', item['title'])
            desc = re.sub(r'<.*?>|&quot;|&gt;|&lt;', '', item['description'])
            
            all_data.append({
                'category': category.replace("ì •ì¹˜ ", ""), # "ì •ì¹˜ ì™¸êµ" -> "ì™¸êµ"
                'title': title,
                'link': item['originallink'] or item['link'],
                'description': desc
            })
            
    save_bulk_to_db(all_data)
    print("\nğŸ‰ ëŒ€ëŸ‰ ìˆ˜ì§‘ ë! ì´ì œ export_csv.pyë¥¼ ì‹¤í–‰í•´ì„œ CSVë¥¼ ë½‘ì•„ì£¼ì„¸ìš”.")

if __name__ == "__main__":
    main()
