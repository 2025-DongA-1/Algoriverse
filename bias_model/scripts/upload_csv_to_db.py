import sys
import os

# ========================================================
# [ì¤‘ìš”] 1. ë¶€ëª¨ í´ë” ê²½ë¡œë¥¼ ë¨¼ì € ì¶”ê°€í•©ë‹ˆë‹¤. (ìˆœì„œ ì¤‘ìš”! â˜…)
# ========================================================
current_dir = os.path.dirname(os.path.abspath(__file__)) # scripts í´ë”
parent_dir = os.path.dirname(current_dir)                # bias_model (ë£¨íŠ¸) í´ë”
sys.path.append(parent_dir)


# ========================================================
# [ì¤‘ìš”] 2. ê·¸ ë‹¤ìŒì— importë¥¼ í•´ì•¼ ì—ëŸ¬ê°€ ì•ˆ ë‚©ë‹ˆë‹¤.
# ========================================================
# (í˜¹ì‹œ ì´ íŒŒì¼ì—ì„œ ë¶„ì„ê¸°ê°€ í•„ìš” ì—†ë‹¤ë©´ ì´ ì¤„ì€ ì§€ì›Œë„ ë©ë‹ˆë‹¤)
try:
    from analysis_service import BiasAnalyzer 
except ImportError:
    pass # ì—…ë¡œë“œë§Œ í•  ë•ŒëŠ” ì—†ì–´ë„ ë˜ë¯€ë¡œ ì—ëŸ¬ ë¬´ì‹œ

# (ì´ ì•„ë˜ì— ì›ë˜ ìˆë˜ import ì½”ë“œë“¤ì´ ì˜¤ë©´ ë©ë‹ˆë‹¤)
from analysis_service import BiasAnalyzer
from dotenv import load_dotenv
import pandas as pd
import pymysql
from tqdm import tqdm

# .env íŒŒì¼ì— ìˆëŠ” ë‚´ìš©ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤
load_dotenv()


# ==========================================
# [ì„¤ì •] DB ì •ë³´
# ==========================================
DB_HOST = os.getenv("DB_HOST")
DB_USER = os.getenv("DB_USER")
DB_PASS = os.getenv("DB_PASS")
DB_NAME = os.getenv("DB_NAME")
DB_PORT = int(os.getenv("DB_PORT"))

# 2. CSV íŒŒì¼ ê²½ë¡œ ìˆ˜ì • (data í´ë” ì•ˆì„ ê°€ë¦¬í‚¤ë„ë¡ ì„¤ì •)
# ì´ë ‡ê²Œ í•˜ë©´ ì–´ë””ì„œ ì‹¤í–‰í•˜ë“  ë¬´ì¡°ê±´ ì •í™•í•œ ìœ„ì¹˜ë¥¼ ì°¾ì•„ëƒ…ë‹ˆë‹¤!
CSV_FILE = os.path.join(parent_dir, 'data', 'algoriverse_corpus_final.csv')

def main():
    # 1. CSV íŒŒì¼ ì½ê¸°
    print(f"ğŸ“‚ '{CSV_FILE}' ë¡œë”© ì¤‘...")
    
    # íŒŒì¼ì´ ì§„ì§œ ìˆëŠ”ì§€ ë¨¼ì € í™•ì¸ (ì¹œì ˆí•œ ì—ëŸ¬ ë©”ì‹œì§€)
    if not os.path.exists(CSV_FILE):
        print(f"âŒ ì˜¤ë¥˜: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
        print(f"ğŸ‘‰ ì°¾ì•„ë³¸ ê²½ë¡œ: {CSV_FILE}")
        return
    
    try:
        df = pd.read_csv(CSV_FILE)
    except:
        df = pd.read_csv(CSV_FILE, encoding='cp949')
        
    print(f"ğŸš€ ì´ {len(df)}ê±´ì˜ ë°ì´í„°ë¥¼ DBì— ì—…ë¡œë“œí•©ë‹ˆë‹¤.")

    # 2. DB ì—°ê²°
    conn = pymysql.connect(host=DB_HOST, user=DB_USER, password=DB_PASS, db=DB_NAME, port=DB_PORT, charset='utf8')
    cur = conn.cursor()

    # 3. ë°ì´í„° ì‚½ì…
    # (ì£¼ì˜: í…Œì´ë¸” ì»¬ëŸ¼ ìˆœì„œë‚˜ ì´ë¦„ì´ ë‹¤ë¥´ë©´ ì—ëŸ¬ ë‚  ìˆ˜ ìˆìœ¼ë‹ˆ INSERT ë¬¸ì„ ì˜ í™•ì¸í•˜ì„¸ìš”)
    # NEWS_ARTICLES í…Œì´ë¸” ì»¬ëŸ¼: category, title, link, description, content(ë³¸ë¬¸ì€ ì—†ìœ¼ë©´ descë¡œ ëŒ€ì²´)
    sql_insert = """
        INSERT INTO NEWS_ARTICLES (category, title, link, description, created_at) 
        VALUES (%s, %s, %s, %s, NOW())
    """

    success_count = 0
    
    try:
        for _, row in tqdm(df.iterrows(), total=len(df)):
            # ë°ì´í„° ì •ì œ (NaN ê°’ì„ ë¹ˆ ë¬¸ìì—´ë¡œ)
            title = row['title'] if pd.notna(row['title']) else ""
            link = row['link'] if pd.notna(row['link']) else ""
            desc = row['description'] if pd.notna(row['description']) else ""
            category = row['category'] if pd.notna(row['category']) else "General"
            
            # ì¤‘ë³µ ë°©ì§€ (ì„ íƒ ì‚¬í•­: ë§í¬ê°€ ì´ë¯¸ ìˆìœ¼ë©´ ê±´ë„ˆë›°ê¸°)
            # ì†ë„ ë•Œë¬¸ì— ì¼ë‹¨ì€ ê·¸ëƒ¥ ë„£ê±°ë‚˜, í•„ìš”í•˜ë©´ ì¤‘ë³µ ì²´í¬ ë¡œì§ ì¶”ê°€
            # ì—¬ê¸°ì„œëŠ” ì¼ë‹¨ ë¬´ì¡°ê±´ INSERT ì‹œë„ (ì—ëŸ¬ë‚˜ë©´ pass)
            try:
                cur.execute(sql_insert, (category, title, link, desc))
                success_count += 1
            except Exception as e:
                # ì¤‘ë³µ ì—ëŸ¬ ë“±ì€ ë¬´ì‹œí•˜ê³  ê³„ì† ì§„í–‰
                pass
                
            if success_count % 500 == 0:
                conn.commit()
                
        conn.commit()
        print(f"\nğŸ‰ ì—…ë¡œë“œ ì™„ë£Œ! ì´ {success_count}ê±´ì´ DBì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
    except Exception as e:
        print(f"âŒ DB ì—°ê²°/ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    finally:
        conn.close()

if __name__ == "__main__":
    main()