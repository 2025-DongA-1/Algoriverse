import pandas as pd
import requests
import re
import pymysql
import time
from tqdm import tqdm
import os
from dotenv import load_dotenv

# .env íŒŒì¼ì— ìˆëŠ” ë‚´ìš©ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤
load_dotenv()

# =============================================================================
# [ì„¤ì •] ì‚¬ìš©ì ì •ë³´ ì…ë ¥
# =============================================================================
NAVER_CLIENT_ID = os.getenv("NAVER_CLIENT_ID")     
NAVER_CLIENT_SECRET = os.getenv("NAVER_CLIENT_SECRET")

# â˜… ì¤‘ìš”: í¬íŠ¸ ë²ˆí˜¸ ìˆ˜ì •!
DB_HOST = os.getenv("DB_HOST")
DB_USER = os.getenv("DB_USER")
DB_PASS = os.getenv("DB_PASS")
DB_NAME = os.getenv("DB_NAME")
DB_PORT = int(os.getenv("DB_PORT"))

DATA_FILE = 'bias_data_final.csv'
TARGET_CATEGORIES = ['ì™¸êµ', 'ì•ˆë³´', 'ì‚¬ë²•', 'ë…¸ë™', 'í™˜ê²½']
NEWS_COUNT = 100 

# =============================================================================
# [ê¸°ëŠ¥ 1] í¸í–¥ ì‚¬ì „ ë¡œë“œ
# =============================================================================
def load_bias_dictionary(filepath):
    try:
        df = pd.read_csv(filepath)
    except FileNotFoundError:
        print(f"âŒ ì˜¤ë¥˜: '{filepath}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return {}
    word_dict = {}
    for _, row in df.iterrows():
        info = {'tendency': row['tendency'], 'weight': row['weight']}
        word_dict[str(row['keyword']).strip()] = info
        if pd.notna(row['synonyms']):
            for syn in str(row['synonyms']).split(','):
                if syn.strip(): word_dict[syn.strip()] = info
    return word_dict

# =============================================================================
# [ê¸°ëŠ¥ 2] í¸í–¥ë„ ê³„ì‚°ê¸°
# =============================================================================
def calculate_bias(text, bias_dict):
    if not bias_dict: return 0, 0, "Error", ""
    score_board = {'ì§„ë³´': 0, 'ë³´ìˆ˜': 0}
    detected_words = []
    
    for word, info in bias_dict.items():
        if word in text:
            score_board[info['tendency']] += info['weight']
            detected_words.append(word)
            
    prog, cons = score_board['ì§„ë³´'], score_board['ë³´ìˆ˜']
    if prog > cons: result = "ì§„ë³´ ìš°ì„¸"
    elif cons > prog: result = "ë³´ìˆ˜ ìš°ì„¸"
    elif prog == 0 and cons == 0: result = "íŒë‹¨ ë¶ˆê°€"
    else: result = "ì¤‘ë¦½"
    
    return prog, cons, result, ", ".join(detected_words)

# =============================================================================
# [ê¸°ëŠ¥ 3] ë„¤ì´ë²„ ë‰´ìŠ¤ ìˆ˜ì§‘
# =============================================================================
def get_naver_news(query, display=10):
    url = "https://openapi.naver.com/v1/search/news.json"
    headers = {"X-Naver-Client-Id": NAVER_CLIENT_ID, "X-Naver-Client-Secret": NAVER_CLIENT_SECRET}
    try:
        res = requests.get(url, headers=headers, params={"query": query, "display": display, "sort": "sim"})
        return res.json().get('items', []) if res.status_code == 200 else []
    except: return []

# =============================================================================
# [ê¸°ëŠ¥ 4] DB ì €ì¥ (í¬íŠ¸ ë²ˆí˜¸ ì¶”ê°€ë¨!)
# =============================================================================
def save_to_db(data_list):
    if not data_list: return
    
    conn = None
    try:
        conn = pymysql.connect(
            host=DB_HOST, 
            user=DB_USER, 
            password=DB_PASS, 
            db=DB_NAME, 
            charset='utf8mb4',
            port=DB_PORT
        )
        cur = conn.cursor()

        # =========================================================
        # [ì¶”ê°€ë¨] í…Œì´ë¸”ì´ ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ ë§Œë“œëŠ” SQL ì‹¤í–‰
        # =========================================================
        create_table_sql = """
        CREATE TABLE IF NOT EXISTS NEWS_ARTICLES (
            id INT AUTO_INCREMENT PRIMARY KEY,
            category VARCHAR(50),
            title VARCHAR(500),
            link VARCHAR(500),
            description TEXT,
            bias_score_prog INT DEFAULT 0,
            bias_score_cons INT DEFAULT 0,
            final_judgment VARCHAR(50),
            detected_keywords TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        ) DEFAULT CHARSET=utf8mb4;
        """
        cur.execute(create_table_sql)
        # =========================================================
        
        sql = """
            INSERT INTO NEWS_ARTICLES 
            (category, title, link, description, bias_score_prog, bias_score_cons, final_judgment, detected_keywords)
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
        """
        
        print("\nğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ ì¤‘...")
        success_cnt = 0
        error_shown = False 
        
        for item in tqdm(data_list, desc="DB Insert"):
            try:
                cur.execute(sql, (
                    item['category'], 
                    item['title'], 
                    item['link'][:999],        
                    item['description'][:2000], 
                    item['prog_score'], 
                    item['cons_score'], 
                    item['judgment'], 
                    item['keywords']
                ))
                success_cnt += 1
            except Exception as e:
                if not error_shown:
                    print(f"\n[âŒ ì €ì¥ ì‹¤íŒ¨ ì›ì¸]: {e}")
                    print(f"[ë¬¸ì œê°€ ëœ ë°ì´í„°]: {item['title']}")
                    error_shown = True
        
        conn.commit()
        print(f"ğŸ‰ ì´ {success_cnt}ê±´ ì €ì¥ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ DB ì ‘ì†/ìƒì„± ì˜¤ë¥˜: {e}")
    finally:
        if conn: conn.close()
# =============================================================================
# [ë©”ì¸] ì‹¤í–‰
# =============================================================================
def main():
    bias_dict = load_bias_dictionary(DATA_FILE)
    if not bias_dict: return
    all_results = []
    print(f"\nğŸš€ ë‰´ìŠ¤ ìˆ˜ì§‘ ë° ë¶„ì„ ì‹œì‘...")

    for category in tqdm(TARGET_CATEGORIES, desc="ì¹´í…Œê³ ë¦¬ë³„ ì§„í–‰"):
        news_items = get_naver_news(f"ì •ì¹˜ {category}", display=NEWS_COUNT)
        for item in news_items:
            title = re.sub(r'<.*?>|&quot;|&gt;|&lt;', '', item['title'])
            desc = re.sub(r'<.*?>|&quot;|&gt;|&lt;', '', item['description'])
            full_text = title + " " + desc
            p, c, res, keys = calculate_bias(full_text, bias_dict)
            all_results.append({
                'category': category, 'title': title, 'link': item['originallink'] or item['link'],
                'description': desc, 'prog_score': p, 'cons_score': c, 'judgment': res, 'keywords': keys
            })
        time.sleep(0.5)

    save_to_db(all_results)

if __name__ == "__main__":
    main()