import pandas as pd
import requests
import re
import time
from tqdm import tqdm
import os
from dotenv import load_dotenv

# .env íŒŒì¼ì— ìˆëŠ” ë‚´ìš©ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤
load_dotenv()


# ==========================================
# [ì„¤ì •] ë³¸ì¸ì˜ API í‚¤ ì…ë ¥
# ==========================================
NAVER_CLIENT_ID = os.getenv("NAVER_CLIENT_ID")     
NAVER_CLIENT_SECRET = os.getenv("NAVER_CLIENT_SECRET") 


# ì½ì–´ì˜¬ í‚¤ì›Œë“œ íŒŒì¼ / ì €ì¥í•  ê²°ê³¼ íŒŒì¼
INPUT_CSV = 'bias_data_final.csv'
OUTPUT_CSV = 'algoriverse_corpus_final.csv'

def main():
    # 1. í‚¤ì›Œë“œ íŒŒì¼ ì½ê¸°
    try:
        df_conf = pd.read_csv(INPUT_CSV)
    except:
        df_conf = pd.read_csv(INPUT_CSV, encoding='cp949')
    
    print(f"ğŸš€ ì´ {len(df_conf)}ê°œ í‚¤ì›Œë“œë¡œ ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤. (DB ì—†ì´ ë°”ë¡œ ì €ì¥)")
    print("   (ì˜ˆìƒ ì†Œìš” ì‹œê°„: 5~10ë¶„)")

    all_news = []

    # 2. ìˆ˜ì§‘ ì‹œì‘
    # í‚¤ì›Œë“œë‹¹ 100ê°œì”©ë§Œ í™•ì‹¤í•˜ê²Œ ê°€ì ¸ì˜µë‹ˆë‹¤. (115ê°œ * 100 = 11,500ê±´ ëª©í‘œ)
    for i, row in tqdm(df_conf.iterrows(), total=len(df_conf), desc="ìˆ˜ì§‘ ì¤‘"):
        keyword = row['keyword']
        category = row['category']
        
        # 'sim'(ê´€ë ¨ë„ìˆœ)ìœ¼ë¡œ í•´ì•¼ ê³¼ê±° 'ê²€ìˆ˜ì™„ë°•' ê°™ì€ ê¸°ì‚¬ê°€ ì¡í™ë‹ˆë‹¤.
        url = "https://openapi.naver.com/v1/search/news.json"
        headers = {"X-Naver-Client-Id": NAVER_CLIENT_ID, "X-Naver-Client-Secret": NAVER_CLIENT_SECRET}
        params = {"query": keyword, "display": 100, "sort": "sim"}
        
        try:
            resp = requests.get(url, headers=headers, params=params, timeout=5)
            if resp.status_code == 200:
                items = resp.json().get('items', [])
                for item in items:
                    title = re.sub(r'<.*?>|&quot;|&gt;|&lt;', '', item['title'])
                    desc = re.sub(r'<.*?>|&quot;|&gt;|&lt;', '', item['description'])
                    
                    all_news.append({
                        'category': category,
                        'title': title,
                        'link': item['originallink'] or item['link'],
                        'description': desc,
                        'content': title + " " + desc  # í•™ìŠµìš© ì»¬ëŸ¼ ë¯¸ë¦¬ ìƒì„±
                    })
            else:
                print(f"API Error ({resp.status_code})")
        except Exception as e:
            print(f"Connection Error: {e}")
        
        time.sleep(0.1) # ì°¨ë‹¨ ë°©ì§€

    # 3. ë°ì´í„°í”„ë ˆì„ ë³€í™˜ ë° ì¤‘ë³µ ì œê±°
    if all_news:
        df_result = pd.DataFrame(all_news)
        print(f"\nğŸ“¥ ìˆ˜ì§‘ëœ ì›ë³¸ ë°ì´í„°: {len(df_result)}ê±´")
        
        # ì¤‘ë³µ ì œê±° (ë§í¬ ê¸°ì¤€)
        df_clean = df_result.drop_duplicates(subset=['link'], keep='first')
        print(f"ğŸ§¹ ì¤‘ë³µ ì œê±° í›„ ìµœì¢… ë°ì´í„°: {len(df_clean)}ê±´")
        
        # íŒŒì¼ ì €ì¥
        df_clean.to_csv(OUTPUT_CSV, index=False, encoding='utf-8-sig')
        print(f"\nğŸ‰ íŒŒì¼ ìƒì„± ì™„ë£Œ: {OUTPUT_CSV}")
        print("â–¶ ì´ íŒŒì¼ì„ Colabì— ì—…ë¡œë“œí•˜ì„¸ìš”!")
    else:
        print("\nâŒ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")

if __name__ == "__main__":
    main()