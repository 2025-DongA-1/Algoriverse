# test_ai.py (VS Codeì—ì„œ ì‹¤í–‰)
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch.nn.functional as F

# í´ë” ê²½ë¡œ (ì••ì¶• í‘¼ í´ë” ì´ë¦„ê³¼ ë˜‘ê°™ì•„ì•¼ í•¨)
MODEL_PATH = "./my_bias_model" 

print(f"ğŸ“‚ ëª¨ë¸ ë¡œë”© ì¤‘... ({MODEL_PATH})")

# 1. ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
try:
    tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)
    model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH)
    print("âœ… ë¡œë”© ì™„ë£Œ! AIê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")
except Exception as e:
    print(f"ğŸš¨ ì˜¤ë¥˜ ë°œìƒ: {e}")
    exit()

# 2. íŒë… í•¨ìˆ˜
def analyze_bias(text):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True)
    with torch.no_grad():
        outputs = model(**inputs)
        probs = F.softmax(outputs.logits, dim=-1)
        
    prob_liberal = probs[0][0].item() * 100
    prob_conservative = probs[0][1].item() * 100
    
    label = "ğŸ”´ ë³´ìˆ˜" if prob_conservative > prob_liberal else "ğŸ”µ ì§„ë³´"
    score = max(prob_conservative, prob_liberal)
    
    print(f"\në¬¸ì¥: {text}")
    print(f"íŒë…: {label} ({score:.1f}%)")

# 3. í…ŒìŠ¤íŠ¸
analyze_bias("ëŒ€í†µë ¹ì˜ ê²°ë‹¨ì´ ê²½ì œë¥¼ ì‚´ë ¸ë‹¤.")
analyze_bias("ê²€ì°° ë…ì¬ ì •ê¶Œì˜ í­ì£¼ë¥¼ ë§‰ì•„ì•¼ í•œë‹¤.")